/* SPDX-License-Identifier: GPL-2.0-only */
/*
 * Based on arch/arm/include/asm/barrier.h
 *
 * Copyright (C) 2012 ARM Ltd.
 * Copyright (C) 2013 Regents of the University of California
 * Copyright (C) 2017 SiFive
 */

#ifndef _ASM_RISCV_BARRIER_H
#define _ASM_RISCV_BARRIER_H

#define nop()		__asm__ __volatile__ ("nop")

#define RISCV_FENCE(p, s) \
	__asm__ __volatile__ ("fence " #p "," #s : : : "memory")

/* These barriers need to enforce ordering on both devices or memory. */
#define mb()		RISCV_FENCE(iorw,iorw)
#define rmb()		RISCV_FENCE(ir,ir)
#define wmb()		RISCV_FENCE(ow,ow)

/* These barriers do not need to enforce ordering on devices, just memory. */
#define __smp_mb()	RISCV_FENCE(rw,rw)
#define __smp_rmb()	RISCV_FENCE(r,r)
#define __smp_wmb()	RISCV_FENCE(w,w)

#define RISCV_ACQUIRE_BARRIER  "\tfence r , rw\n"
#define RISCV_RELEASE_BARRIER  "\tfence rw,  w\n"

#define __smp_store_release(p, v)				\
do {								\
	RISCV_FENCE(rw, w);					\
	*(p) = (v);						\
} while (0)

#define __smp_load_acquire(p)					\
({								\
	typeof(*p) ___p1 = *(p);				\
	RISCV_FENCE(r, rw);					\
	___p1;							\
})

#define __WRITE_ONCE(x, val)						\
do {									\
	*(volatile typeof(x) *)&(x) = (val);				\
} while (0)

#define WRITE_ONCE(x, val)						\
do {									\
	__WRITE_ONCE(x, val);						\
} while (0)

#define __READ_ONCE(x)	(*(const volatile typeof(x) *)&(x))

#define READ_ONCE(x)							\
({									\
	__READ_ONCE(x);							\
})

#endif /* _ASM_RISCV_BARRIER_H */
